{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbfa9c37",
   "metadata": {},
   "source": [
    "# 불안정한 그레이디언트 문제와 싸우기\n",
    "tf.keras를 사용해 간단한 메모리 셀 안에 층 정규화를 구현해보겠습니다.<br>\n",
    "이렇게 하려면 사용자 정의 메모리 셀을 정의해야 합니다.<br>\n",
    "이 층은 call() 메소드가 다음 두 개의 매개변수를 받는 것을 제외하고는 일반적인 층입니다.\n",
    "\n",
    "현재 타임 스텝의 inputs와 이전 타임 스텝의 은닉 states입니다.<br>\n",
    "states 매개변수는 하나 이상의 텐서를 담은 리스트입니다.\n",
    "\n",
    "셀은 state_size와 output_size 속성을 가져야 합니다.<br>\n",
    "간단한 RNN에서는 둘 다 모두 유닛 개수와 동일합니다.<br>\n",
    "다음 코드는 SimpleRNNCell 처럼 작동하는 사용자 정의 메모리 셀을 구현합니다.<br>\n",
    "각 타임 스텝마다 층 정규화를 적용한다는 점이 다릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8a5e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f347e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
    "                                                          activation=None)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if inputs is not None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            dtype = inputs.dtype\n",
    "        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]\n",
    "    def call(self, inputs, states):\n",
    "        # 현재 입력과 이전 은닉 상태의 선형 조합 계산\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        # 층 정규화와 활성화 함수를 차례대로 적용\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        # 출력과 은닉 상태 반환\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2df518ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 7s 25ms/step - loss: 0.1368 - last_time_step_mse: 0.1209 - val_loss: 0.0731 - val_last_time_step_mse: 0.0596\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0626 - last_time_step_mse: 0.0512 - val_loss: 0.0572 - val_last_time_step_mse: 0.0444\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0521 - last_time_step_mse: 0.0394 - val_loss: 0.0493 - val_last_time_step_mse: 0.0358\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0469 - last_time_step_mse: 0.0340 - val_loss: 0.0449 - val_last_time_step_mse: 0.0314\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0430 - last_time_step_mse: 0.0296 - val_loss: 0.0409 - val_last_time_step_mse: 0.0272\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0389 - last_time_step_mse: 0.0249 - val_loss: 0.0378 - val_last_time_step_mse: 0.0226\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0360 - last_time_step_mse: 0.0220 - val_loss: 0.0350 - val_last_time_step_mse: 0.0213\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0340 - last_time_step_mse: 0.0203 - val_loss: 0.0330 - val_last_time_step_mse: 0.0190\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0324 - last_time_step_mse: 0.0188 - val_loss: 0.0314 - val_last_time_step_mse: 0.0175\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0313 - last_time_step_mse: 0.0176 - val_loss: 0.0307 - val_last_time_step_mse: 0.0172\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0306 - last_time_step_mse: 0.0173 - val_loss: 0.0300 - val_last_time_step_mse: 0.0164\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0299 - last_time_step_mse: 0.0165 - val_loss: 0.0294 - val_last_time_step_mse: 0.0160\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0292 - last_time_step_mse: 0.0158 - val_loss: 0.0292 - val_last_time_step_mse: 0.0159\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0291 - last_time_step_mse: 0.0157 - val_loss: 0.0287 - val_last_time_step_mse: 0.0157\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0288 - last_time_step_mse: 0.0152 - val_loss: 0.0284 - val_last_time_step_mse: 0.0149\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0281 - last_time_step_mse: 0.0149 - val_loss: 0.0280 - val_last_time_step_mse: 0.0148\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0279 - last_time_step_mse: 0.0148 - val_loss: 0.0274 - val_last_time_step_mse: 0.0141\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0275 - last_time_step_mse: 0.0144 - val_loss: 0.0272 - val_last_time_step_mse: 0.0141\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0275 - last_time_step_mse: 0.0143 - val_loss: 0.0269 - val_last_time_step_mse: 0.0138\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 5s 25ms/step - loss: 0.0270 - last_time_step_mse: 0.0139 - val_loss: 0.0266 - val_last_time_step_mse: 0.0136\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
    "                     input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3133d8e",
   "metadata": {},
   "source": [
    "비슷하게 타임 스텝 사이에 드롭아웃을 적용하는 사용자 정의 셀을 만들 수 있습니다.<br>\n",
    "하지만 이는 그냥 keras.layers.RNN을 제외한 모든 순환 층과 케라스에서 제공하는 모든 셀은 dropout 매개변수(타임 스텝마다 입력에 적용하는 드롭아웃 비율)와 recurrent_dropout 매개변수(타임 스텝마다 은닉 상태에 대한 드롭아웃 비율)를 지원하므로 따로 사용자 정의 셀을 만들 필요는 없습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
